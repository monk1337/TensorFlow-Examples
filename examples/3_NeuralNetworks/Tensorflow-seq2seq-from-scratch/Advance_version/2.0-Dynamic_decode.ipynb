{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Dynamic_decode.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "5AG3fkVjUHWB",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#importing libraries\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a_4x39yIVFHu",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#for dynamic_decode we need => decoder , maximum_iteration (max_time in batch )\n",
        "\n",
        "   #for decoder we need ==> cell , helper , intial_state , output layer\n",
        "     \n",
        "        # for helper we need ==> input_batch , sequence_length\n",
        "       \n",
        "              #let's go one by one\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QkYpDgeRVyt2",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#helper function\n",
        "\n",
        "input_data = np.random.randn(8,5,6).astype(np.float32)\n",
        "max_sequence_length = 5\n",
        "batch_size = 8\n",
        "\n",
        "sequence_length = [2,4,5,3,2,5,7,8] #same size of batch\n",
        "\n",
        "helper_function = tf.contrib.seq2seq.TrainingHelper(input_data,sequence_length,time_major=False)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9GmBz-lUWy7M",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#decoder \n",
        "\n",
        "cell=tf.contrib.rnn.LSTMCell(32)\n",
        "\n",
        "initial_state = cell.zero_state(batch_size=batch_size,dtype=tf.float32)\n",
        "\n",
        "vocab_size = 104\n",
        "\n",
        "output_layer = tf.layers.Dense(vocab_size)\n",
        "\n",
        "basic_decoder = tf.contrib.seq2seq.BasicDecoder(cell,helper_function,initial_state,output_layer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uslJWcG3XnBG",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "b73e8cb6-17d8-43fa-9650-f85107abc001",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530626226873,
          "user_tz": -330,
          "elapsed": 1501,
          "user": {
            "displayName": "ayodhyankit paul",
            "photoUrl": "//lh3.googleusercontent.com/-aLSMOExWjxQ/AAAAAAAAAAI/AAAAAAAAAAc/yPMgEhPgnpk/s50-c-k-no/photo.jpg",
            "userId": "106815194044651409765"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#step decode\n",
        "\n",
        "#we can manually decode step by step\n",
        "\n",
        "#let's decode by one single step\n",
        "\n",
        "initial_finished,initial_input,inital_state = basic_decoder.initialize()\n",
        "\n",
        "step_output , step_state, next_input , step_finished=  basic_decoder.step(tf.constant(3),initial_input,initial_state)\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  rnn_output,lstm_tuple,next_input,step_finished = sess.run([step_output,step_state,next_input,step_finished])\n",
        "  \n",
        "  output , sample_id = rnn_output\n",
        "  \n",
        "  Memory , state_hidden_output = lstm_tuple\n",
        "  \n",
        "  print(output.shape)       #rnn_output                          #batch x vocab_size\n",
        "  \n",
        "  print(sample_id)         #argmax over rnn output               #batch_size\n",
        "  \n",
        "  print(Memory.shape)             #memory of state                #batch_size x lstm_hidden_size\n",
        "  \n",
        "  print(state_hidden_output.shape)    #hidden_output of state     #batch_size x lstm_hidden_size\n",
        "  \n",
        "  print(next_input.shape)        #next output for decoder state   #batch x dim\n",
        "  \n",
        "  print(step_finished)             #finished indication\n",
        "  \n",
        "  \n",
        "  "
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8, 104)\n",
            "[ 50 103  48 102  48  81  99 102]\n",
            "(8, 32)\n",
            "(8, 32)\n",
            "(8, 6)\n",
            "[ True  True False  True  True False False False]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Cl1Vmo4nYE3e",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#now instead of doing this manually we want a loop , so it will unroll the rnn till all step finished , for that you can use\n",
        "#your own loop , but tensorflow have function called dynamic_decode let's try that\n",
        "\n",
        "\n",
        "dynam_decode = tf.contrib.seq2seq.dynamic_decode(basic_decoder,output_time_major=False,maximum_iterations=8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "632aUyfzc-YQ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "073b2375-3290-47cd-813f-c1f9e8cf8873",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530627118255,
          "user_tz": -330,
          "elapsed": 1170,
          "user": {
            "displayName": "ayodhyankit paul",
            "photoUrl": "//lh3.googleusercontent.com/-aLSMOExWjxQ/AAAAAAAAAAI/AAAAAAAAAAc/yPMgEhPgnpk/s50-c-k-no/photo.jpg",
            "userId": "106815194044651409765"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#it will return \n",
        "\n",
        "#logits\n",
        "#sample_id\n",
        "# lstm_tuple\n",
        "#final_finished\n",
        "\n",
        "rnn_output , lstm_tuple , final_finished = dynam_decode\n",
        "\n",
        "\n",
        "output , sample_id = rnn_output  \n",
        "print(output.shape)   #batch x max_time x vocab\n",
        "print(sample_id)      #batch size\n",
        "\n",
        "last_state_memory , last_state_hidden_output = lstm_tuple\n",
        "\n",
        "print(last_state_memory.shape)    #batch x lstm_hidden_size\n",
        "\n",
        "print(last_state_hidden_output.shape)  #batch x lstm_hidden_size\n",
        "\n",
        "print(final_finished)\n",
        "\n",
        "\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8, ?, 104)\n",
            "Tensor(\"decoder_1/transpose_1:0\", shape=(8, ?), dtype=int32)\n",
            "(8, 32)\n",
            "(8, 32)\n",
            "Tensor(\"decoder_1/while/Exit_8:0\", shape=(8,), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "e-l4-ep9eccn",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
