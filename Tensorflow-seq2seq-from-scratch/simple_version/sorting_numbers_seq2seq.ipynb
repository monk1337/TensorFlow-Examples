{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-30T18:50:13.788603Z",
     "start_time": "2018-06-30T18:50:13.783803Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "#reference : https://arxiv.org/pdf/1409.3215.pdf\n",
    "#probem statement is  given a sequence [6,2,5,1,3]  seq_2seq will learn and do short the sequence [1,2,3,5,6]\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import numpy as np\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-30T18:50:14.827080Z",
     "start_time": "2018-06-30T18:50:14.817786Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#some hyper parameters\n",
    "\n",
    "encoder_vocab_size = 100  # suppose our encoding data vocab size is 100 \n",
    "decoder_vocab_size = 150  # and decoding data vocab size is 150\n",
    "\n",
    "batch_size=10\n",
    "\n",
    "encoder_hidden_unit = 100\n",
    "decoder_hidden_unit = 100\n",
    "\n",
    "encoder_embedding_dim=50\n",
    "decoder_embedding_dim=50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-30T18:50:15.926532Z",
     "start_time": "2018-06-30T18:50:15.913006Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"encoder_input:0\", shape=(?, ?), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "#inputs :  encoder_input , decoder_input , decoder_target\n",
    "\n",
    "\n",
    "encoder_input = tf.placeholder(name='encoder_input',shape=[None,None],dtype=tf.int32)\n",
    "decoder_input = tf.placeholder(name='decoder_input',shape=[None,None],dtype=tf.int32)\n",
    "decoder_target= tf.placeholder(name='decoder_target',shape=[None,None],dtype=tf.int32)\n",
    "\n",
    "#ecoder input should be  [Max_time,batch]  time major  \n",
    "#decoder input should be [Max_time,batch]  time major\n",
    "#decoder_target should be [Max_time,batch] time major\n",
    "print(encoder_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-30T18:50:17.108003Z",
     "start_time": "2018-06-30T18:50:17.077151Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"embedding_lookup:0\", shape=(?, ?, 50), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#embedding for encoder , decoder\n",
    "\n",
    "\n",
    "\n",
    "#use tf.get_variable instead of tf.Variable\n",
    "encoder_embedding = tf.get_variable(name='encoder_embedding',\n",
    "                                    shape=[encoder_vocab_size,encoder_embedding_dim],\n",
    "                                    dtype=tf.float32,\n",
    "                                    initializer=tf.random_uniform_initializer(-0.01,0.01))\n",
    "\n",
    "decoder_embedding = tf.get_variable(name='decoder_embedding',\n",
    "                                    shape=[decoder_vocab_size,decoder_embedding_dim],\n",
    "                                    dtype=tf.float32,\n",
    "                                    initializer=tf.random_uniform_initializer(-0.01,0.01))\n",
    "\n",
    "embedd_encoder = tf.nn.embedding_lookup(encoder_embedding,encoder_input)\n",
    "#now encoder input will become [ max_time , batch_size , embedding_dim ]\n",
    "\n",
    "embedd_decoder = tf.nn.embedding_lookup(decoder_embedding,decoder_input)\n",
    "#now decoder input will become [ max_time , batch_size , embedding_dim ]\n",
    "\n",
    "print(embedd_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-30T18:50:19.211425Z",
     "start_time": "2018-06-30T18:50:19.205812Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#cell for rnn\n",
    "\n",
    "encoder_cell = rnn.LSTMCell(num_units=encoder_hidden_unit)\n",
    "decoder_cell = rnn.LSTMCell(num_units=decoder_hidden_unit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-30T18:50:20.406582Z",
     "start_time": "2018-06-30T18:50:20.266266Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#encoder\n",
    "\n",
    "encoder_model, encoder_last_state = tf.nn.dynamic_rnn(cell=encoder_cell,\n",
    "                                                      inputs=embedd_encoder,\n",
    "                                                      time_major=True,\n",
    "                                                      dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-30T18:50:22.149576Z",
     "start_time": "2018-06-30T18:50:22.021865Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#decoder \n",
    "decoder_output,decoder_last_state= tf.nn.dynamic_rnn(cell=decoder_cell,\n",
    "                                                     inputs=embedd_decoder,\n",
    "                                                     time_major=True,\n",
    "                                                     initial_state=encoder_last_state,\n",
    "                                                     dtype=tf.float32,\n",
    "                                                     scope='decoder_inputs')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-30T18:50:23.328495Z",
     "start_time": "2018-06-30T18:50:23.250940Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#projection layer without activation\n",
    "\n",
    "linear_projection = tf.contrib.layers.fully_connected(decoder_output,decoder_vocab_size)\n",
    "\n",
    "\n",
    "#taking max argument\n",
    "prediction = tf.argmax(linear_projection,2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-30T18:50:25.414696Z",
     "start_time": "2018-06-30T18:50:25.366434Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=tf.one_hot(decoder_target,\n",
    "                                                     depth=decoder_vocab_size,dtype=tf.float32),\n",
    "                                                     logits=linear_projection)\n",
    "\n",
    "#reduce_mean\n",
    "loss=tf.reduce_mean(cross_entropy)\n",
    "\n",
    "#our aim is to minimize this loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-30T18:50:28.061567Z",
     "start_time": "2018-06-30T18:50:27.385508Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data=np.load('data_to_be_train.npy')\n",
    "\n",
    "train_data_int=int(len(data)*0.90)\n",
    "\n",
    "train_data = data[:train_data_int]\n",
    "test_data  = data[train_data_int:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PAD=0\n",
    "EOS=1\n",
    "def get_train_batch(value):\n",
    "    train_data_ = train_data[value]\n",
    "    max_len = max([len(i) for i in train_data_])\n",
    "#     print(max_len)\n",
    "    pad_data=[i+[0]*(max_len-len(i)) for i in train_data_ if len(i)<max_len]\n",
    "    \n",
    "    encoder_inpu   = pad_data\n",
    "    decoder_inpu   = [[EOS] + sorted(i) for i in pad_data]\n",
    "    decoder_target = [sorted(i) +[EOS] + [0]*(max_len-len(i)) for i in train_data_ if len(i)<max_len]\n",
    "#     print(encoder_inpu)\n",
    "#     print('\\n')\n",
    "#     print(decoder_inpu)\n",
    "#     print('\\n')\n",
    "#     print(decoder_target)\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    return {'encoder':np.transpose(np.array(encoder_inpu),[1,0]),\n",
    "            'decoder_':np.transpose(np.array(decoder_inpu),[1,0]),\n",
    "            'decoder_tar':np.transpose(np.array(decoder_target),[1,0])}\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "# [[4, 6, 4, 8, 0, 0, 0, 0, 0], [7, 9, 2, 8, 2, 7, 3, 6, 0], [4, 3, 0, 0, 0, 0, 0, 0, 0], [6, 4, 0, 0, 0, 0, 0, 0, 0], [6, 4, 0, 0, 0, 0, 0, 0, 0], [5, 6, 0, 0, 0, 0, 0, 0, 0], [6, 7, 5, 3, 5, 2, 2, 9, 0], [5, 5, 8, 6, 4, 4, 2, 0, 0], [4, 9, 4, 0, 0, 0, 0, 0, 0]]\n",
    "\n",
    "\n",
    "# [[1, 0, 0, 0, 0, 0, 4, 4, 6, 8], [1, 0, 2, 2, 3, 6, 7, 7, 8, 9], [1, 0, 0, 0, 0, 0, 0, 0, 3, 4], [1, 0, 0, 0, 0, 0, 0, 0, 4, 6], [1, 0, 0, 0, 0, 0, 0, 0, 4, 6], [1, 0, 0, 0, 0, 0, 0, 0, 5, 6], [1, 0, 2, 2, 3, 5, 5, 6, 7, 9], [1, 0, 0, 2, 4, 4, 5, 5, 6, 8], [1, 0, 0, 0, 0, 0, 0, 4, 4, 9]]\n",
    "\n",
    "\n",
    "# [[4, 4, 6, 8, 1, 0, 0, 0, 0, 0], [2, 2, 3, 6, 7, 7, 8, 9, 1, 0], [3, 4, 1, 0, 0, 0, 0, 0, 0, 0], [4, 6, 1, 0, 0, 0, 0, 0, 0, 0], [4, 6, 1, 0, 0, 0, 0, 0, 0, 0], [5, 6, 1, 0, 0, 0, 0, 0, 0, 0], [2, 2, 3, 5, 5, 6, 7, 9, 1, 0], [2, 4, 4, 5, 5, 6, 8, 1, 0, 0], [4, 4, 9, 1, 0, 0, 0, 0, 0, 0]]\n",
    "# None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c48d234a8e504bc48cfa242d60a304b3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "batch 0\n",
      "  minibatch loss: 0.8562768697738647\n",
      "    input     > [[7 8 2 8 5 7 4 3 5]\n",
      " [2 6 5 3 2 9 3 9 8]\n",
      " [9 9 5 8 6 6 7 2 7]\n",
      " [4 2 0 5 0 6 4 7 5]\n",
      " [7 2 0 5 0 3 7 0 5]\n",
      " [0 0 0 0 0 4 6 0 0]\n",
      " [0 0 0 0 0 9 7 0 0]\n",
      " [0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0]]\n",
      "    predicted > [[3 2 2 3 3 3 2 2 4]\n",
      " [5 4 4 5 5 5 4 4 5]\n",
      " [7 5 7 7 7 5 5 7 7]\n",
      " [8 7 1 8 1 7 5 9 8]\n",
      " [9 9 0 9 0 8 7 1 9]\n",
      " [1 1 0 1 0 8 8 0 1]\n",
      " [0 0 0 0 0 9 9 0 0]\n",
      " [0 0 0 0 0 1 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0]]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de8d359270d74dc8b321d5c827f78d09"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "batch 1\n",
      "  minibatch loss: 0.0724317654967308\n",
      "    input     > [[7 8 2 8 5 7 4 3 5]\n",
      " [2 6 5 3 2 9 3 9 8]\n",
      " [9 9 5 8 6 6 7 2 7]\n",
      " [4 2 0 5 0 6 4 7 5]\n",
      " [7 2 0 5 0 3 7 0 5]\n",
      " [0 0 0 0 0 4 6 0 0]\n",
      " [0 0 0 0 0 9 7 0 0]\n",
      " [0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0]]\n",
      "    predicted > [[2 2 2 3 2 3 3 2 5]\n",
      " [4 2 5 5 5 4 4 3 5]\n",
      " [7 6 5 5 6 6 4 7 5]\n",
      " [7 8 1 7 1 6 6 9 7]\n",
      " [9 9 0 8 0 7 7 1 7]\n",
      " [1 1 0 1 0 9 7 0 1]\n",
      " [0 0 0 0 0 9 7 0 0]\n",
      " [0 0 0 0 0 1 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0]]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39002cedf0c9429b8be8a881828dbc20"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "batch 2\n",
      "  minibatch loss: 0.0035553080961108208\n",
      "    input     > [[7 8 2 8 5 7 4 3 5]\n",
      " [2 6 5 3 2 9 3 9 8]\n",
      " [9 9 5 8 6 6 7 2 7]\n",
      " [4 2 0 5 0 6 4 7 5]\n",
      " [7 2 0 5 0 3 7 0 5]\n",
      " [0 0 0 0 0 4 6 0 0]\n",
      " [0 0 0 0 0 9 7 0 0]\n",
      " [0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0]]\n",
      "    predicted > [[2 2 2 3 2 3 3 2 5]\n",
      " [4 2 5 5 5 4 4 3 5]\n",
      " [7 6 5 5 6 6 4 7 5]\n",
      " [7 8 1 8 1 6 6 9 7]\n",
      " [9 9 0 8 0 7 7 1 8]\n",
      " [1 1 0 1 0 9 7 0 1]\n",
      " [0 0 0 0 0 9 7 0 0]\n",
      " [0 0 0 0 0 1 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0]]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56ccc3d4145647c69052bed422c64012"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "batch 3\n",
      "  minibatch loss: 0.0007402679184451699\n",
      "    input     > [[7 8 2 8 5 7 4 3 5]\n",
      " [2 6 5 3 2 9 3 9 8]\n",
      " [9 9 5 8 6 6 7 2 7]\n",
      " [4 2 0 5 0 6 4 7 5]\n",
      " [7 2 0 5 0 3 7 0 5]\n",
      " [0 0 0 0 0 4 6 0 0]\n",
      " [0 0 0 0 0 9 7 0 0]\n",
      " [0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0]]\n",
      "    predicted > [[2 2 2 3 2 3 3 2 5]\n",
      " [4 2 5 5 5 4 4 3 5]\n",
      " [7 6 5 5 6 6 4 7 5]\n",
      " [7 8 1 8 1 6 6 9 7]\n",
      " [9 9 0 8 0 7 7 1 8]\n",
      " [1 1 0 1 0 9 7 0 1]\n",
      " [0 0 0 0 0 9 7 0 0]\n",
      " [0 0 0 0 0 1 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0]]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de87d46c77ff45969196fc7a3ea4eb58"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "batch 4\n",
      "  minibatch loss: 0.0006132316193543375\n",
      "    input     > [[7 8 2 8 5 7 4 3 5]\n",
      " [2 6 5 3 2 9 3 9 8]\n",
      " [9 9 5 8 6 6 7 2 7]\n",
      " [4 2 0 5 0 6 4 7 5]\n",
      " [7 2 0 5 0 3 7 0 5]\n",
      " [0 0 0 0 0 4 6 0 0]\n",
      " [0 0 0 0 0 9 7 0 0]\n",
      " [0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0]]\n",
      "    predicted > [[2 2 2 3 2 3 3 2 5]\n",
      " [4 2 5 5 5 4 4 3 5]\n",
      " [7 6 5 5 6 6 4 7 5]\n",
      " [7 8 1 8 1 6 6 9 7]\n",
      " [9 9 0 8 0 7 7 1 8]\n",
      " [1 1 0 1 0 9 7 0 1]\n",
      " [0 0 0 0 0 9 7 0 0]\n",
      " [0 0 0 0 0 1 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0]]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb32b32b6e1f4bf6bb1c0ae1203b0417"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-88158b9ca680>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mtr_da\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_train_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mencoder_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtr_da\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoder'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecoder_target\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtr_da\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'decoder_tar'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecoder_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtr_da\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'decoder_'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0mloss_track\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ANANT/apal/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ANANT/apal/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ANANT/apal/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ANANT/apal/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ANANT/apal/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook as tq\n",
    "max_batches = 30\n",
    "batches_in_epoch = 1\n",
    "loss_track = []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for batch in range(max_batches):\n",
    "        for j in tq(range(len(train_data))):\n",
    "            tr_da = get_train_batch(j)\n",
    "            feed_dict={encoder_input:tr_da['encoder'],decoder_target:tr_da['decoder_tar'],decoder_input:tr_da['decoder_']}\n",
    "            _, l = sess.run([train, loss],feed_dict)\n",
    "            loss_track.append(l)\n",
    "\n",
    "        if batch == 0 or batch % batches_in_epoch == 0:\n",
    "            print('batch {}'.format(batch))\n",
    "            print('  minibatch loss: {}'.format(sess.run(loss,feed_dict)))\n",
    "            predict_ = sess.run(prediction, feed_dict)\n",
    "            \n",
    "            print('    input     > {}'.format(tr_da['encoder']))\n",
    "            print('    predicted > {}'.format(predict_))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.0009 after 102940 examples (batch_size=10)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(loss_track)\n",
    "print('loss {:.4f} after {} examples (batch_size={})'.format(loss_track[-1], len(loss_track)*batch_size, batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
