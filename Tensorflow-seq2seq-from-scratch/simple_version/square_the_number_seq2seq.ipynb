{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-30T18:50:13.788603Z",
     "start_time": "2018-06-30T18:50:13.783803Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "#reference : https://arxiv.org/pdf/1409.3215.pdf\n",
    "#probem statement is  given a sequence [2,3,4,5,6]  seq_2seq will learn and do square of each number [4,9,16,25,36]\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import numpy as np\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-30T18:50:14.827080Z",
     "start_time": "2018-06-30T18:50:14.817786Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#some hyper parameters\n",
    "\n",
    "encoder_vocab_size = 100  # suppose our encoding data vocab size is 100 \n",
    "decoder_vocab_size = 150  # and decoding data vocab size is 150\n",
    "\n",
    "batch_size=10\n",
    "\n",
    "encoder_hidden_unit = 100\n",
    "decoder_hidden_unit = 100\n",
    "\n",
    "encoder_embedding_dim=50\n",
    "decoder_embedding_dim=50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-30T18:50:15.926532Z",
     "start_time": "2018-06-30T18:50:15.913006Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"encoder_input:0\", shape=(?, ?), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "#inputs :  encoder_input , decoder_input , decoder_target\n",
    "\n",
    "\n",
    "encoder_input = tf.placeholder(name='encoder_input',shape=[None,None],dtype=tf.int32)\n",
    "decoder_input = tf.placeholder(name='decoder_input',shape=[None,None],dtype=tf.int32)\n",
    "decoder_target= tf.placeholder(name='decoder_target',shape=[None,None],dtype=tf.int32)\n",
    "\n",
    "#ecoder input should be  [Max_time,batch]  time major  \n",
    "#decoder input should be [Max_time,batch]  time major\n",
    "#decoder_target should be [Max_time,batch] time major\n",
    "print(encoder_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-30T18:50:17.108003Z",
     "start_time": "2018-06-30T18:50:17.077151Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"embedding_lookup:0\", shape=(?, ?, 50), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#embedding for encoder , decoder\n",
    "\n",
    "\n",
    "\n",
    "#use tf.get_variable instead of tf.Variable\n",
    "encoder_embedding = tf.get_variable(name='encoder_embedding',\n",
    "                                    shape=[encoder_vocab_size,encoder_embedding_dim],\n",
    "                                    dtype=tf.float32,\n",
    "                                    initializer=tf.random_uniform_initializer(-0.01,0.01))\n",
    "\n",
    "decoder_embedding = tf.get_variable(name='decoder_embedding',\n",
    "                                    shape=[decoder_vocab_size,decoder_embedding_dim],\n",
    "                                    dtype=tf.float32,\n",
    "                                    initializer=tf.random_uniform_initializer(-0.01,0.01))\n",
    "\n",
    "embedd_encoder = tf.nn.embedding_lookup(encoder_embedding,encoder_input)\n",
    "#now encoder input will become [ max_time , batch_size , embedding_dim ]\n",
    "\n",
    "embedd_decoder = tf.nn.embedding_lookup(decoder_embedding,decoder_input)\n",
    "#now decoder input will become [ max_time , batch_size , embedding_dim ]\n",
    "\n",
    "print(embedd_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-30T18:50:19.211425Z",
     "start_time": "2018-06-30T18:50:19.205812Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#cell for rnn\n",
    "\n",
    "encoder_cell = rnn.LSTMCell(num_units=encoder_hidden_unit)\n",
    "decoder_cell = rnn.LSTMCell(num_units=decoder_hidden_unit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-30T18:50:20.406582Z",
     "start_time": "2018-06-30T18:50:20.266266Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#encoder\n",
    "\n",
    "encoder_model, encoder_last_state = tf.nn.dynamic_rnn(cell=encoder_cell,\n",
    "                                                      inputs=embedd_encoder,\n",
    "                                                      time_major=True,\n",
    "                                                      dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-30T18:50:22.149576Z",
     "start_time": "2018-06-30T18:50:22.021865Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#decoder \n",
    "decoder_output,decoder_last_state= tf.nn.dynamic_rnn(cell=decoder_cell,\n",
    "                                                     inputs=embedd_decoder,\n",
    "                                                     time_major=True,\n",
    "                                                     initial_state=encoder_last_state,\n",
    "                                                     dtype=tf.float32,\n",
    "                                                     scope='decoder_inputs')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-30T18:50:23.328495Z",
     "start_time": "2018-06-30T18:50:23.250940Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#projection layer without activation\n",
    "\n",
    "linear_projection = tf.contrib.layers.fully_connected(decoder_output,decoder_vocab_size)\n",
    "\n",
    "\n",
    "#taking max argument\n",
    "prediction = tf.argmax(linear_projection,2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-30T18:50:25.414696Z",
     "start_time": "2018-06-30T18:50:25.366434Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=tf.one_hot(decoder_target,\n",
    "                                                     depth=decoder_vocab_size,dtype=tf.float32),\n",
    "                                                     logits=linear_projection)\n",
    "\n",
    "#reduce_mean\n",
    "loss=tf.reduce_mean(cross_entropy)\n",
    "\n",
    "#our aim is to minimize this loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-30T18:50:28.061567Z",
     "start_time": "2018-06-30T18:50:27.385508Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data=np.load('data_to_be_train.npy')\n",
    "\n",
    "train_data_int=int(len(data)*0.80)\n",
    "\n",
    "train_data = data[:train_data_int]\n",
    "test_data  = data[train_data_int:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PAD=0\n",
    "EOS=1\n",
    "def get_train_batch(value):\n",
    "    train_data_ = train_data[value]\n",
    "    max_len = max([len(i) for i in train_data_])\n",
    "#     print(max_len)\n",
    "    pad_data=[i+[0]*(max_len-len(i)) for i in train_data_ if len(i)<max_len]\n",
    "    \n",
    "    encoder_inpu   = pad_data\n",
    "    decoder_inpu   = [[EOS] + [j*j for j in i ] for i in pad_data]\n",
    "    decoder_target = [[j*j for j in i] +[EOS] + [0]*(max_len-len(i)) for i in train_data_ if len(i)<max_len]\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    return {'encoder':np.transpose(np.array(encoder_inpu),[1,0]),\n",
    "            'decoder_':np.transpose(np.array(decoder_inpu),[1,0]),\n",
    "            'decoder_tar':np.transpose(np.array(decoder_target),[1,0])}\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e911c40485224a6d94c590f34790c818"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "batch 0\n",
      "  minibatch loss: 1.759526014328003\n",
      "    input     > [[4 6 2 6 6 7 8 5 2]\n",
      " [6 6 8 6 3 8 9 3 3]\n",
      " [3 9 2 8 9 3 9 6 2]\n",
      " [0 2 8 9 5 8 0 2 4]\n",
      " [0 6 4 4 3 9 0 0 0]\n",
      " [0 0 0 7 2 9 0 0 0]\n",
      " [0 0 0 8 2 2 0 0 0]\n",
      " [0 0 0 0 3 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0]]\n",
      "    predicted > [[16 16 16 16  9 49 16 16  9]\n",
      " [16 16 16 16 49 49 16 16 49]\n",
      " [ 4 16 16 16 49 49  4 16 49]\n",
      " [ 1 16 16 16 49 49  1  4 49]\n",
      " [ 0  4  4 16 49 49  0  1  1]\n",
      " [ 0  1  1 81 49 49  0  0  0]\n",
      " [ 0  0  0  4 49 49  0  0  0]\n",
      " [ 0  0  0  1  4  1  0  0  0]\n",
      " [ 0  0  0  0  1  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0]]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b89b57f743e42419e1f1e69972fd200"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "batch 1\n",
      "  minibatch loss: 0.5196203589439392\n",
      "    input     > [[4 6 2 6 6 7 8 5 2]\n",
      " [6 6 8 6 3 8 9 3 3]\n",
      " [3 9 2 8 9 3 9 6 2]\n",
      " [0 2 8 9 5 8 0 2 4]\n",
      " [0 6 4 4 3 9 0 0 0]\n",
      " [0 0 0 7 2 9 0 0 0]\n",
      " [0 0 0 8 2 2 0 0 0]\n",
      " [0 0 0 0 3 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0]]\n",
      "    predicted > [[16 36  4 36 36 49 25 36 81]\n",
      " [36 36 36 36  9 36 81  9 81]\n",
      " [49 81  4 16 16  9 81 36  4]\n",
      " [ 1 81 64 81 25  4  1 81 16]\n",
      " [ 0 36 16 16  9 81  0  1  1]\n",
      " [ 0  1  1  4 81 81  0  0  0]\n",
      " [ 0  0  0 16 81  4  0  0  0]\n",
      " [ 0  0  0  1 49  1  0  0  0]\n",
      " [ 0  0  0  0  1  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0]]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6673b84905d34bcda7957f4b687f4492"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "batch 2\n",
      "  minibatch loss: 0.269411563873291\n",
      "    input     > [[4 6 2 6 6 7 8 5 2]\n",
      " [6 6 8 6 3 8 9 3 3]\n",
      " [3 9 2 8 9 3 9 6 2]\n",
      " [0 2 8 9 5 8 0 2 4]\n",
      " [0 6 4 4 3 9 0 0 0]\n",
      " [0 0 0 7 2 9 0 0 0]\n",
      " [0 0 0 8 2 2 0 0 0]\n",
      " [0 0 0 0 3 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0]]\n",
      "    predicted > [[16 36  4 36 36 49 25 25  4]\n",
      " [36 36 25 36  9 25 81  9  9]\n",
      " [ 9 81  4 16  4 49 81 36  4]\n",
      " [ 1  4 64 81 25 25  1  4 16]\n",
      " [ 0 36 16 16  9  4  0  1  1]\n",
      " [ 0  1  1 49  4  4  0  0  0]\n",
      " [ 0  0  0 64  9 64  0  0  0]\n",
      " [ 0  0  0  1  9  1  0  0  0]\n",
      " [ 0  0  0  0  1  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0]]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "913c9c27012d44aa821489d36337ccbc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "batch 3\n",
      "  minibatch loss: 0.1046612560749054\n",
      "    input     > [[4 6 2 6 6 7 8 5 2]\n",
      " [6 6 8 6 3 8 9 3 3]\n",
      " [3 9 2 8 9 3 9 6 2]\n",
      " [0 2 8 9 5 8 0 2 4]\n",
      " [0 6 4 4 3 9 0 0 0]\n",
      " [0 0 0 7 2 9 0 0 0]\n",
      " [0 0 0 8 2 2 0 0 0]\n",
      " [0 0 0 0 3 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0]]\n",
      "    predicted > [[16 36  4 36 36 49 64 25  4]\n",
      " [36 36 64 36  9 64 81  9  9]\n",
      " [ 9 81  4 64 81  9 81 36  4]\n",
      " [ 1  4 64 81 25 64  1  4 16]\n",
      " [ 0 36 16 16  9 81  0  1  1]\n",
      " [ 0  1  1 49  4 81  0  0  0]\n",
      " [ 0  0  0 64  9  4  0  0  0]\n",
      " [ 0  0  0  1  9  1  0  0  0]\n",
      " [ 0  0  0  0  1  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0]]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecd008888d514e8b9b02c340da693554"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "batch 4\n",
      "  minibatch loss: 0.030690694227814674\n",
      "    input     > [[4 6 2 6 6 7 8 5 2]\n",
      " [6 6 8 6 3 8 9 3 3]\n",
      " [3 9 2 8 9 3 9 6 2]\n",
      " [0 2 8 9 5 8 0 2 4]\n",
      " [0 6 4 4 3 9 0 0 0]\n",
      " [0 0 0 7 2 9 0 0 0]\n",
      " [0 0 0 8 2 2 0 0 0]\n",
      " [0 0 0 0 3 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0]]\n",
      "    predicted > [[16 36  4 36 36 49 64 25  4]\n",
      " [36 36 64 36  9 64 81  9  9]\n",
      " [ 9 81  4 64 81  9 81 36  4]\n",
      " [ 1  4 64 81 25 64  1  4 16]\n",
      " [ 0 36 16 16  9 81  0  1  1]\n",
      " [ 0  1  1 49  4 81  0  0  0]\n",
      " [ 0  0  0 64  4  4  0  0  0]\n",
      " [ 0  0  0  1  9  1  0  0  0]\n",
      " [ 0  0  0  0  1  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0]]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad5f706682854f2cab967e8f7e400e3a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "batch 5\n",
      "  minibatch loss: 0.015287562273442745\n",
      "    input     > [[4 6 2 6 6 7 8 5 2]\n",
      " [6 6 8 6 3 8 9 3 3]\n",
      " [3 9 2 8 9 3 9 6 2]\n",
      " [0 2 8 9 5 8 0 2 4]\n",
      " [0 6 4 4 3 9 0 0 0]\n",
      " [0 0 0 7 2 9 0 0 0]\n",
      " [0 0 0 8 2 2 0 0 0]\n",
      " [0 0 0 0 3 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0]]\n",
      "    predicted > [[16 36  4 36 36 49 64 25  4]\n",
      " [36 36 64 36  9 64 81  9  9]\n",
      " [ 9 81  4 64 81  9 81 36  4]\n",
      " [ 1  4 64 81 25 64  1  4 16]\n",
      " [ 0 36 16 16  9 81  0  1  1]\n",
      " [ 0  1  1 49  4 81  0  0  0]\n",
      " [ 0  0  0 64  4  4  0  0  0]\n",
      " [ 0  0  0  1  9  1  0  0  0]\n",
      " [ 0  0  0  0  1  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0]]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d5b472686394910a9764aaec18a8a75"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "batch 6\n",
      "  minibatch loss: 0.012834947556257248\n",
      "    input     > [[4 6 2 6 6 7 8 5 2]\n",
      " [6 6 8 6 3 8 9 3 3]\n",
      " [3 9 2 8 9 3 9 6 2]\n",
      " [0 2 8 9 5 8 0 2 4]\n",
      " [0 6 4 4 3 9 0 0 0]\n",
      " [0 0 0 7 2 9 0 0 0]\n",
      " [0 0 0 8 2 2 0 0 0]\n",
      " [0 0 0 0 3 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0]]\n",
      "    predicted > [[16 36  4 36 36 49 64 25  4]\n",
      " [36 36 64 36  9 64 81  9  9]\n",
      " [ 9 81  4 64 81  9 81 36  4]\n",
      " [ 1  4 64 81 25 64  1  4 16]\n",
      " [ 0 36 16 16  9 81  0  1  1]\n",
      " [ 0  1  1 49  4 81  0  0  0]\n",
      " [ 0  0  0 64  4  4  0  0  0]\n",
      " [ 0  0  0  1  9  1  0  0  0]\n",
      " [ 0  0  0  0  1  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0]]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dc54576b9104a31ba0d1052632506a5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "batch 7\n",
      "  minibatch loss: 0.011493828147649765\n",
      "    input     > [[4 6 2 6 6 7 8 5 2]\n",
      " [6 6 8 6 3 8 9 3 3]\n",
      " [3 9 2 8 9 3 9 6 2]\n",
      " [0 2 8 9 5 8 0 2 4]\n",
      " [0 6 4 4 3 9 0 0 0]\n",
      " [0 0 0 7 2 9 0 0 0]\n",
      " [0 0 0 8 2 2 0 0 0]\n",
      " [0 0 0 0 3 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0]]\n",
      "    predicted > [[16 36  4 36 36 49 64 25  4]\n",
      " [36 36 64 36  9 64 81  9  9]\n",
      " [ 9 81  4 64 81  9 81 36  4]\n",
      " [ 1  4 64 81 25 64  1  4 16]\n",
      " [ 0 36 16 16  9 81  0  1  1]\n",
      " [ 0  1  1 49  4 81  0  0  0]\n",
      " [ 0  0  0 64  4  4  0  0  0]\n",
      " [ 0  0  0  1  9  1  0  0  0]\n",
      " [ 0  0  0  0  1  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0]]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f666e63eb2ae4376bc05646880e8f815"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-88158b9ca680>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mtr_da\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_train_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mencoder_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtr_da\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoder'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecoder_target\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtr_da\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'decoder_tar'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecoder_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtr_da\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'decoder_'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0mloss_track\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ANANT/apal/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ANANT/apal/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ANANT/apal/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ANANT/apal/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ANANT/apal/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook as tq\n",
    "max_batches = 30\n",
    "batches_in_epoch = 1\n",
    "loss_track = []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for batch in range(max_batches):\n",
    "        for j in tq(range(len(train_data))):\n",
    "            tr_da = get_train_batch(j)\n",
    "            feed_dict={encoder_input:tr_da['encoder'],decoder_target:tr_da['decoder_tar'],decoder_input:tr_da['decoder_']}\n",
    "            _, l = sess.run([train, loss],feed_dict)\n",
    "            loss_track.append(l)\n",
    "\n",
    "        if batch == 0 or batch % batches_in_epoch == 0:\n",
    "            print('batch {}'.format(batch))\n",
    "            print('  minibatch loss: {}'.format(sess.run(loss,feed_dict)))\n",
    "            predict_ = sess.run(prediction, feed_dict)\n",
    "            \n",
    "            print('    input     > {}'.format(tr_da['encoder']))\n",
    "            print('    predicted > {}'.format(predict_))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.0025 after 132910 examples (batch_size=10)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niEiEUXCLiEQYBbeISIRRcIuIRJj/B1Q9gZ/L/udAAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(loss_track)\n",
    "print('loss {:.4f} after {} examples (batch_size={})'.format(loss_track[-1], len(loss_track)*batch_size, batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
