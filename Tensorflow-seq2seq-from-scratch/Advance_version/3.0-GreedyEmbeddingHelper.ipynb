{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GreedyEmbeddingHelper.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "L4qy0_ECF5iK",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#importing libraries \n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "tf.reset_default_graph()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vBavuZfEGWZP",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#during training we feed target_embedded_input to decoder but during inference we don't have target so we feed \n",
        "\n",
        "# decoder vocabulary as target \n",
        "\n",
        "#during training we pass embedd_input to TrainingHelper\n",
        "#during inference we pass embedding_matrix to GreedyEmbeddingHelper\n",
        "\n",
        "#parameter of GreedyEmbeddingHelper  ==>  embedding , start token , end token\n",
        "\n",
        "#start token should be vector of batch length with start token \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7JtSb8JYGyQ-",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "symbols = {'PAD':0,'GO':1,'EOS':2}\n",
        "\n",
        "vocab_size=12\n",
        "hidden_dim = 20\n",
        "batch_size = 13\n",
        "\n",
        "\n",
        "#defining random numbers for matrix , one can use Glove or Word2vec or other embeddings\n",
        "\n",
        "embedding_matrix = tf.get_variable(name='matrix',shape=[vocab_size,hidden_dim],\n",
        "                                   dtype=tf.float32,\n",
        "                                   initializer=tf.random_uniform_initializer(-0.01,0.01))\n",
        "\n",
        "#let's make vector for start token\n",
        "\n",
        "start_token = tf.tile(tf.constant([symbols['GO']],dtype=tf.int32),[batch_size])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7VEHDkA3HgWp",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#let's define greedy embedding Helper\n",
        "\n",
        "#nputs are  = > embedding , start_token , end_token\n",
        "\n",
        "greed_embedd = tf.contrib.seq2seq.GreedyEmbeddingHelper(embedding_matrix,start_token,symbols['EOS'])\n",
        "\n",
        "initialize_embed= greed_embedd.initialize()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5tnCAKPjIiV9",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "e5cdd8b2-bb66-4b7f-dcf2-6b3d0f8ef5bc",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530654999077,
          "user_tz": -330,
          "elapsed": 1071,
          "user": {
            "displayName": "ayodhyankit paul",
            "photoUrl": "//lh3.googleusercontent.com/-aLSMOExWjxQ/AAAAAAAAAAI/AAAAAAAAAAc/yPMgEhPgnpk/s50-c-k-no/photo.jpg",
            "userId": "106815194044651409765"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#output will be [batch_size x embedding_dm] for each_time step , currently we it is creating output  for one timestep.\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  steps_finished , output_for_state = sess.run(initialize_embed)\n",
        "  \n",
        "  print(steps_finished)          #current rnn is not unfold for any time step so all False\n",
        "  print(output_for_state.shape)  #batch x embedding_dm"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[False False False False False False False False False False False False\n",
            " False]\n",
            "(13, 20)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PBnF50-5JMY-",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
