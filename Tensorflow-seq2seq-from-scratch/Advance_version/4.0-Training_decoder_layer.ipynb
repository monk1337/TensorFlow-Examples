{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Training_decoder_layer.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "J05XWt8ELzb3",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-gC4KRSXL-p_",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "batch_size=5\n",
        "max_time=4\n",
        "sequence_length = [2,3,4,2,1]\n",
        "dim=10\n",
        "vocab_size = 7\n",
        "\n",
        "\n",
        "input_data = np.random.randn(batch_size, max_time ,dim).astype(np.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9TphyYCRMVa9",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#training_helper\n",
        "\n",
        "Helper_function = tf.contrib.seq2seq.TrainingHelper(input_data,sequence_length,time_major=False)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "scpaEzYdMogQ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#Basic_decoder\n",
        "\n",
        "#LSTM cell\n",
        "cell = tf.contrib.rnn.LSTMCell(num_units=9)\n",
        "\n",
        "#Initial_state\n",
        "initial_sta = cell.zero_state(batch_size=batch_size,dtype=tf.float32)\n",
        "\n",
        "#output a.k.a Projection layer\n",
        "projection = tf.layers.Dense(vocab_size)\n",
        "\n",
        "\n",
        "basic_decoder = tf.contrib.seq2seq.BasicDecoder(cell,Helper_function,initial_sta,projection)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hIARtT7vNYu-",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "75c1df8f-4999-46e5-8478-3871e026ac3f",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530656798707,
          "user_tz": -330,
          "elapsed": 1280,
          "user": {
            "displayName": "ayodhyankit paul",
            "photoUrl": "//lh3.googleusercontent.com/-aLSMOExWjxQ/AAAAAAAAAAI/AAAAAAAAAAc/yPMgEhPgnpk/s50-c-k-no/photo.jpg",
            "userId": "106815194044651409765"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#dynamic_decode\n",
        "#input are  decoder , max_iteration , since we which is max_len of seq across batch\n",
        "dynamic_decoder = tf.contrib.seq2seq.dynamic_decode(basic_decoder,maximum_iterations=max_time,impute_finished=True)\n",
        "\n",
        "#output will be first_finished , rnn_output , Lstm_tuple\n",
        "\n",
        "# rnn_output==> input for next step \n",
        "# sample_id===> argmax over logits\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  rnn_output , Lstm_tuple , first_finished = sess.run(dynamic_decoder)\n",
        " \n",
        "  \n",
        "  print(rnn_output[0].shape)\n",
        "  \n",
        "  #it will return batch x max_time x vocab_size\n",
        "  \n",
        "  print(Lstm_tuple[0].shape)\n",
        "  \n",
        "  #batch x lstm_dim  { final state output }\n",
        "  \n",
        "  print(first_finished)\n",
        "  \n",
        "  #batch_size length vector\n",
        "  \n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5, 4, 7)\n",
            "(5, 9)\n",
            "[2 3 4 2 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BV59KQrlOBTA",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
